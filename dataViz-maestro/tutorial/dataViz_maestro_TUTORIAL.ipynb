{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì dataViz-maestro: Tutorial Completo de Business Intelligence\n",
    "\n",
    "## Proyecto End-to-End desde Cero hasta Dashboards Profesionales\n",
    "\n",
    "**Instructor:** Tu Profesor de BI y Analytics  \n",
    "**Nivel:** Intermedio a Avanzado  \n",
    "**Duraci√≥n:** 2-3 horas (con pr√°ctica)  \n",
    "**Requisitos previos:** Conocimientos b√°sicos de SQL, Python, y conceptos de BI\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Tabla de Contenidos\n",
    "\n",
    "1. [Introducci√≥n al Proyecto](#1-introduccion)\n",
    "2. [Fundamentos de Star Schema](#2-star-schema)\n",
    "3. [Dise√±o de Base de Datos SQL](#3-diseno-sql)\n",
    "4. [Python ETL - Data Loading](#4-python-etl)\n",
    "5. [Transformaciones y KPIs](#5-transformaciones)\n",
    "6. [Validaci√≥n de Calidad de Datos](#6-validacion)\n",
    "7. [Consultas SQL Avanzadas](#7-sql-avanzado)\n",
    "8. [Power BI y DAX](#8-power-bi)\n",
    "9. [Dashboards Web Interactivos](#9-dashboards-web)\n",
    "10. [Best Practices y Conclusiones](#10-conclusiones)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducci√≥n al Proyecto üéØ\n",
    "\n",
    "### ¬øQu√© vamos a construir?\n",
    "\n",
    "En este tutorial, construiremos un **Data Warehouse empresarial completo** que demuestra las habilidades esenciales de un analista de BI profesional:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  FUENTES DE DATOS                                           ‚îÇ\n",
    "‚îÇ  ‚Ä¢ CSV Files  ‚Ä¢ Excel  ‚Ä¢ APIs  ‚Ä¢ SQL Databases              ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                        ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  CAPA ETL (Python)                                          ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Extracci√≥n  ‚Ä¢ Transformaci√≥n  ‚Ä¢ Validaci√≥n               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                        ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  DATA WAREHOUSE (SQL Server)                                ‚îÇ\n",
    "‚îÇ  ‚Ä¢ Star Schema  ‚Ä¢ 21 Tablas  ‚Ä¢ 43K+ Registros               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                        ‚Üì\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚Üì                                ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   POWER BI       ‚îÇ          ‚îÇ  WEB DASHBOARDS  ‚îÇ\n",
    "‚îÇ   Dashboards     ‚îÇ          ‚îÇ  (HTML + Chart.js)‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üéØ Objetivos de Aprendizaje\n",
    "\n",
    "Al finalizar este tutorial, ser√°s capaz de:\n",
    "\n",
    "‚úÖ Dise√±ar un **star schema** robusto para an√°lisis empresarial  \n",
    "‚úÖ Escribir **SQL avanzado** con CTEs, window functions, y optimizaciones  \n",
    "‚úÖ Construir **ETL pipelines** en Python con OOP y mejores pr√°cticas  \n",
    "‚úÖ Implementar **validaci√≥n de calidad de datos** automatizada  \n",
    "‚úÖ Crear **dashboards profesionales** en Power BI y web  \n",
    "‚úÖ Aplicar **KPIs y m√©tricas** de negocio correctamente  \n",
    "\n",
    "### üìä Dominios de Negocio Cubiertos\n",
    "\n",
    "| Dominio | Tablas | M√©tricas Clave |\n",
    "|---------|--------|----------------|\n",
    "| **Ventas** | 3 tablas | Revenue, Conversion Rate, Customer LTV |\n",
    "| **Contabilidad** | 2 tablas | P&L, Cash Flow, Budget vs Actual |\n",
    "| **Log√≠stica** | 3 tablas | Inventory Levels, On-Time Delivery |\n",
    "| **Producci√≥n** | 3 tablas | OEE, Defect Rate, Cycle Time |\n",
    "| **Recursos Humanos** | 2 tablas | Headcount, Overtime, Absenteeism |\n",
    "\n",
    "### üõ†Ô∏è Tecnolog√≠as Utilizadas\n",
    "\n",
    "- **Base de Datos:** SQL Server 2019+ (o Express Edition)\n",
    "- **Python:** 3.8+ con Pandas, PyODBC, Flask\n",
    "- **BI:** Power BI Desktop\n",
    "- **Web:** HTML5, CSS3, Bootstrap 5, Chart.js\n",
    "- **Herramientas:** Jupyter Notebook, VS Code, SSMS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fundamentos de Star Schema ‚≠ê\n",
    "\n",
    "### ¬øPor qu√© Star Schema?\n",
    "\n",
    "El **star schema** es el dise√±o m√°s popular en Data Warehousing porque:\n",
    "\n",
    "1. **Simplicidad:** F√°cil de entender para usuarios de negocio\n",
    "2. **Performance:** Queries r√°pidas con menos JOINs\n",
    "3. **Escalabilidad:** F√°cil agregar nuevas dimensiones o hechos\n",
    "4. **BI-Friendly:** Optimizado para herramientas como Power BI\n",
    "\n",
    "### Anatom√≠a de un Star Schema\n",
    "\n",
    "```\n",
    "                    dim_date\n",
    "                        ‚îÇ\n",
    "                        ‚îÇ\n",
    "    dim_customer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ dim_product\n",
    "                        ‚îÇ\n",
    "                        ‚îÇ\n",
    "                 fact_transactions  ‚Üê Tabla de Hechos (Centro)\n",
    "                        ‚îÇ\n",
    "                        ‚îÇ\n",
    "    dim_warehouse ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ dim_supplier\n",
    "                        ‚îÇ\n",
    "                        ‚îÇ\n",
    "                 dim_production_line\n",
    "```\n",
    "\n",
    "### Conceptos Clave\n",
    "\n",
    "#### üì¶ Tablas de Dimensiones (Descriptivas)\n",
    "\n",
    "**Qu√© son:** Contienen informaci√≥n descriptiva sobre el negocio  \n",
    "**Caracter√≠sticas:**\n",
    "- Relativamente peque√±as (decenas a miles de filas)\n",
    "- Cambian lentamente (Slowly Changing Dimensions)\n",
    "- Contienen atributos textuales y categ√≥ricos\n",
    "\n",
    "**Ejemplo:**\n",
    "```sql\n",
    "dim_customer\n",
    "‚îú‚îÄ‚îÄ customer_id (PK)      ‚Üí Identificador √∫nico\n",
    "‚îú‚îÄ‚îÄ customer_name         ‚Üí Atributo descriptivo\n",
    "‚îú‚îÄ‚îÄ segment               ‚Üí Categor√≠a (Premium, Standard, Budget)\n",
    "‚îú‚îÄ‚îÄ region                ‚Üí Geograf√≠a\n",
    "‚îî‚îÄ‚îÄ is_vip                ‚Üí Flag booleano\n",
    "```\n",
    "\n",
    "#### üìä Tablas de Hechos (M√©tricas)\n",
    "\n",
    "**Qu√© son:** Contienen mediciones cuantitativas del negocio  \n",
    "**Caracter√≠sticas:**\n",
    "- Muy grandes (millones a billones de filas)\n",
    "- Granularidad espec√≠fica (ej: transacci√≥n individual)\n",
    "- Contienen foreign keys a dimensiones + medidas num√©ricas\n",
    "\n",
    "**Ejemplo:**\n",
    "```sql\n",
    "fact_transactions\n",
    "‚îú‚îÄ‚îÄ transaction_id (PK)   ‚Üí Identificador √∫nico\n",
    "‚îú‚îÄ‚îÄ date_id (FK)          ‚Üí Foreign key a dim_date\n",
    "‚îú‚îÄ‚îÄ product_id (FK)       ‚Üí Foreign key a dim_product\n",
    "‚îú‚îÄ‚îÄ customer_id (FK)      ‚Üí Foreign key a dim_customer\n",
    "‚îú‚îÄ‚îÄ quantity              ‚Üí Medida aditiva\n",
    "‚îú‚îÄ‚îÄ revenue               ‚Üí Medida aditiva\n",
    "‚îî‚îÄ‚îÄ gross_margin_pct      ‚Üí Medida derivada\n",
    "```\n",
    "\n",
    "### üéì Mejores Pr√°cticas del Dise√±o\n",
    "\n",
    "1. **Dimensi√≥n de Fecha:** SIEMPRE incluir una dimensi√≥n de fecha completa\n",
    "   - Permite an√°lisis temporal (YoY, MTD, QTD)\n",
    "   - Pre-calculada para mejor performance\n",
    "\n",
    "2. **Surrogate Keys:** Usar IDs artificiales en vez de claves naturales\n",
    "   - Permite manejar cambios en claves de negocio\n",
    "   - Mejor performance en JOINs\n",
    "\n",
    "3. **Granularidad:** Definir claramente el nivel de detalle\n",
    "   - Cada fila debe representar UN evento de negocio\n",
    "   - Ejemplo: Una transacci√≥n, una orden, un movimiento\n",
    "\n",
    "4. **Medidas Aditivas:** Preferir m√©tricas que se puedan sumar\n",
    "   - ‚úÖ Revenue (se puede sumar)\n",
    "   - ‚úÖ Quantity (se puede sumar)\n",
    "   - ‚ùå Percentage (NO se puede sumar directamente)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dise√±o de Base de Datos SQL üóÑÔ∏è\n",
    "\n",
    "### Estructura de Nuestro Data Warehouse\n",
    "\n",
    "Vamos a crear un DW con **21 tablas** organizadas as√≠:\n",
    "\n",
    "```\n",
    "DIMENSIONES (7 tablas)\n",
    "‚îú‚îÄ‚îÄ dim_date           ‚Üí Calendario completo 2023-2025 (1,095 filas)\n",
    "‚îú‚îÄ‚îÄ dim_product        ‚Üí Cat√°logo de productos (30 filas)\n",
    "‚îú‚îÄ‚îÄ dim_customer       ‚Üí Clientes B2B y B2C (25 filas)\n",
    "‚îú‚îÄ‚îÄ dim_warehouse      ‚Üí Ubicaciones f√≠sicas (8 filas)\n",
    "‚îú‚îÄ‚îÄ dim_supplier       ‚Üí Proveedores (10 filas)\n",
    "‚îú‚îÄ‚îÄ dim_production_line‚Üí L√≠neas de producci√≥n (8 filas)\n",
    "‚îî‚îÄ‚îÄ dim_employee       ‚Üí Empleados (50 filas)\n",
    "\n",
    "HECHOS (14 tablas)\n",
    "‚îú‚îÄ‚îÄ VENTAS\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ fact_transactions     ‚Üí Transacciones principales (10,000 filas)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ sales_orders          ‚Üí √ìrdenes de venta (5,000 filas)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ sales_commission      ‚Üí Comisiones de ventas\n",
    "‚îú‚îÄ‚îÄ CONTABILIDAD\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ accounting_gl_master  ‚Üí Cat√°logo de cuentas\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ accounting_journal_entries ‚Üí Asientos contables\n",
    "‚îú‚îÄ‚îÄ LOG√çSTICA\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ logistics_inventory   ‚Üí Inventario (6,000 filas)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ logistics_shipments   ‚Üí Env√≠os (4,500 filas)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ logistics_inventory_movement ‚Üí Movimientos\n",
    "‚îú‚îÄ‚îÄ PRODUCCI√ìN\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ production_work_orders ‚Üí √ìrdenes de trabajo (3,000 filas)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ production_defects    ‚Üí Control de defectos\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ production_efficiency_metrics ‚Üí M√©tricas OEE (4,000 filas)\n",
    "‚îî‚îÄ‚îÄ RH\n",
    "    ‚îú‚îÄ‚îÄ hr_payroll            ‚Üí N√≥mina\n",
    "    ‚îî‚îÄ‚îÄ hr_attendance         ‚Üí Asistencia\n",
    "```\n",
    "\n",
    "### Vamos a Crear la Dimensi√≥n de Fecha\n",
    "\n",
    "Esta es la dimensi√≥n M√ÅS IMPORTANTE en cualquier DW. Veamos por qu√©:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Primero, importemos las librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pyodbc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(f\"üìä Pandas versi√≥n: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy versi√≥n: {np.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Lecci√≥n: Creaci√≥n de Dimensi√≥n de Fecha en Python\n",
    "\n",
    "**¬øPor qu√© crear una dimensi√≥n de fecha?**\n",
    "\n",
    "1. **Pre-c√°lculo:** Todos los atributos de fecha (a√±o, trimestre, mes) ya est√°n calculados\n",
    "2. **Performance:** Evita c√°lculos repetitivos en cada query\n",
    "3. **Consistencia:** Misma l√≥gica de calendario para todos los an√°lisis\n",
    "4. **Flexibilidad:** Permite calendarios fiscales, d√≠as laborales, festivos\n",
    "\n",
    "Vamos a crear 3 a√±os de datos (2023-2025):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def crear_dimension_fecha(fecha_inicio='2023-01-01', fecha_fin='2025-12-31'):\n",
    "    \"\"\"\n",
    "    Crea una dimensi√≥n de fecha completa con todos los atributos necesarios.\n",
    "    \n",
    "    Explicaci√≥n paso a paso:\n",
    "    1. Generamos un rango de fechas\n",
    "    2. Extraemos componentes (a√±o, mes, d√≠a, etc.)\n",
    "    3. Calculamos atributos derivados (trimestre, semana, etc.)\n",
    "    4. Agregamos l√≥gica de negocio (festivos, d√≠as laborales)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paso 1: Crear rango de fechas\n",
    "    print(\"üìÖ Paso 1: Generando rango de fechas...\")\n",
    "    fechas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq='D')\n",
    "    df = pd.DataFrame({'full_date': fechas})\n",
    "    print(f\"   ‚úì {len(df)} fechas generadas\")\n",
    "    \n",
    "    # Paso 2: Extraer componentes b√°sicos\n",
    "    print(\"üìÖ Paso 2: Extrayendo componentes de fecha...\")\n",
    "    df['date_id'] = df['full_date'].dt.strftime('%Y%m%d').astype(int)\n",
    "    df['year_number'] = df['full_date'].dt.year\n",
    "    df['month_number'] = df['full_date'].dt.month\n",
    "    df['month_name'] = df['full_date'].dt.month_name()\n",
    "    df['day_of_month'] = df['full_date'].dt.day\n",
    "    df['day_of_week'] = df['full_date'].dt.dayofweek + 1  # Lunes=1, Domingo=7\n",
    "    df['day_name'] = df['full_date'].dt.day_name()\n",
    "    df['day_of_year'] = df['full_date'].dt.dayofyear\n",
    "    print(\"   ‚úì Componentes b√°sicos extra√≠dos\")\n",
    "    \n",
    "    # Paso 3: Calcular trimestre (Quarter)\n",
    "    print(\"üìÖ Paso 3: Calculando trimestres...\")\n",
    "    df['quarter'] = df['full_date'].dt.quarter\n",
    "    df['quarter_name'] = 'Q' + df['quarter'].astype(str)\n",
    "    print(\"   ‚úì Trimestres calculados\")\n",
    "    \n",
    "    # Paso 4: Calcular a√±o/trimestre/mes FISCAL (inicia en Julio)\n",
    "    print(\"üìÖ Paso 4: Calculando calendario fiscal...\")\n",
    "    # Si el mes >= 7 (Julio-Diciembre), a√±o fiscal = a√±o actual + 1\n",
    "    df['fiscal_year'] = df.apply(\n",
    "        lambda x: x['year_number'] + 1 if x['month_number'] >= 7 else x['year_number'],\n",
    "        axis=1\n",
    "    )\n",
    "    # Trimestre fiscal\n",
    "    df['fiscal_quarter'] = df['month_number'].apply(\n",
    "        lambda m: 1 if m in [7,8,9] else 2 if m in [10,11,12] else 3 if m in [1,2,3] else 4\n",
    "    )\n",
    "    print(\"   ‚úì Calendario fiscal calculado\")\n",
    "    \n",
    "    # Paso 5: Identificar fines de semana y d√≠as laborales\n",
    "    print(\"üìÖ Paso 5: Identificando d√≠as laborales...\")\n",
    "    df['is_weekend'] = df['day_of_week'].isin([6, 7]).astype(int)  # S√°bado y Domingo\n",
    "    df['is_working_day'] = (~df['is_weekend'].astype(bool)).astype(int)\n",
    "    print(\"   ‚úì D√≠as laborales identificados\")\n",
    "    \n",
    "    # Paso 6: Marcar festivos (simplificado - USA)\n",
    "    print(\"üìÖ Paso 6: Marcando d√≠as festivos...\")\n",
    "    df['is_holiday'] = 0\n",
    "    df['holiday_name'] = None\n",
    "    \n",
    "    # A√±o Nuevo\n",
    "    df.loc[(df['month_number'] == 1) & (df['day_of_month'] == 1), 'is_holiday'] = 1\n",
    "    df.loc[(df['month_number'] == 1) & (df['day_of_month'] == 1), 'holiday_name'] = \"New Year's Day\"\n",
    "    \n",
    "    # Navidad\n",
    "    df.loc[(df['month_number'] == 12) & (df['day_of_month'] == 25), 'is_holiday'] = 1\n",
    "    df.loc[(df['month_number'] == 12) & (df['day_of_month'] == 25), 'holiday_name'] = 'Christmas Day'\n",
    "    \n",
    "    # D√≠a de la Independencia (USA)\n",
    "    df.loc[(df['month_number'] == 7) & (df['day_of_month'] == 4), 'is_holiday'] = 1\n",
    "    df.loc[(df['month_number'] == 7) & (df['day_of_month'] == 4), 'holiday_name'] = 'Independence Day'\n",
    "    \n",
    "    print(f\"   ‚úì {df['is_holiday'].sum()} d√≠as festivos marcados\")\n",
    "    \n",
    "    # Paso 7: Calcular semanas\n",
    "    print(\"üìÖ Paso 7: Calculando semanas...\")\n",
    "    df['week_of_year'] = df['full_date'].dt.isocalendar().week\n",
    "    df['week_of_month'] = (df['day_of_month'] - 1) // 7 + 1\n",
    "    print(\"   ‚úì Semanas calculadas\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Dimensi√≥n de fecha creada exitosamente!\")\n",
    "    print(f\"\\nüìä Resumen:\")\n",
    "    print(f\"   Total fechas: {len(df):,}\")\n",
    "    print(f\"   Rango: {df['full_date'].min().date()} a {df['full_date'].max().date()}\")\n",
    "    print(f\"   D√≠as laborales: {df['is_working_day'].sum():,}\")\n",
    "    print(f\"   Fines de semana: {df['is_weekend'].sum():,}\")\n",
    "    print(f\"   D√≠as festivos: {df['is_holiday'].sum():,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Crear la dimensi√≥n\n",
    "dim_date = crear_dimension_fecha()\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"\\nüìã Primeras 5 filas de dim_date:\")\n",
    "print(dim_date.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualicemos la Dimensi√≥n de Fecha\n",
    "\n",
    "Vamos a crear algunas visualizaciones para entender mejor nuestra dimensi√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Crear figura con subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('üìä An√°lisis de la Dimensi√≥n de Fecha', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribuci√≥n de d√≠as por a√±o\n",
    "dim_date.groupby('year_number').size().plot(\n",
    "    kind='bar', ax=axes[0,0], color='steelblue'\n",
    ")\n",
    "axes[0,0].set_title('D√≠as por A√±o')\n",
    "axes[0,0].set_xlabel('A√±o')\n",
    "axes[0,0].set_ylabel('Cantidad de D√≠as')\n",
    "\n",
    "# 2. Distribuci√≥n de d√≠as laborales vs fines de semana\n",
    "working_days = dim_date.groupby('year_number')['is_working_day'].sum()\n",
    "weekend_days = dim_date.groupby('year_number')['is_weekend'].sum()\n",
    "x = np.arange(len(working_days))\n",
    "width = 0.35\n",
    "axes[0,1].bar(x - width/2, working_days, width, label='D√≠as Laborales', color='green')\n",
    "axes[0,1].bar(x + width/2, weekend_days, width, label='Fines de Semana', color='orange')\n",
    "axes[0,1].set_title('D√≠as Laborales vs Fines de Semana por A√±o')\n",
    "axes[0,1].set_xlabel('A√±o')\n",
    "axes[0,1].set_ylabel('Cantidad de D√≠as')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(working_days.index)\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. D√≠as por mes (promedio de todos los a√±os)\n",
    "dias_por_mes = dim_date.groupby('month_number').size() / 3  # Dividir por 3 a√±os\n",
    "axes[1,0].plot(dias_por_mes.index, dias_por_mes.values, marker='o', linewidth=2, markersize=8)\n",
    "axes[1,0].set_title('Promedio de D√≠as por Mes')\n",
    "axes[1,0].set_xlabel('Mes')\n",
    "axes[1,0].set_ylabel('D√≠as Promedio')\n",
    "axes[1,0].set_xticks(range(1, 13))\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distribuci√≥n por trimestre\n",
    "dim_date.groupby('quarter').size().plot(\n",
    "    kind='pie', ax=axes[1,1], autopct='%1.1f%%',\n",
    "    colors=['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    ")\n",
    "axes[1,1].set_title('Distribuci√≥n de D√≠as por Trimestre')\n",
    "axes[1,1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observaciones importantes:\")\n",
    "print(\"   ‚Ä¢ Cada a√±o tiene ~365 d√≠as (366 en a√±os bisiestos)\")\n",
    "print(\"   ‚Ä¢ Aproximadamente 71% d√≠as laborales, 29% fines de semana\")\n",
    "print(\"   ‚Ä¢ Febrero tiene menos d√≠as que otros meses\")\n",
    "print(\"   ‚Ä¢ Los trimestres tienen distribuci√≥n similar\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Python ETL - Data Loading üîÑ\n",
    "\n",
    "### ¬øQu√© es ETL?\n",
    "\n",
    "**ETL** significa **E**xtract, **T**ransform, **L**oad:\n",
    "\n",
    "```\n",
    "EXTRACT (Extraer)\n",
    "    ‚Üì\n",
    "    ‚Ä¢ Leer datos de m√∫ltiples fuentes\n",
    "    ‚Ä¢ CSV, Excel, Bases de datos, APIs\n",
    "    ‚Ä¢ Validar conectividad\n",
    "    ‚Üì\n",
    "TRANSFORM (Transformar)\n",
    "    ‚Üì\n",
    "    ‚Ä¢ Limpiar datos (nulls, duplicados)\n",
    "    ‚Ä¢ Calcular m√©tricas derivadas\n",
    "    ‚Ä¢ Aplicar reglas de negocio\n",
    "    ‚Ä¢ Agregar/filtrar/enriquecer\n",
    "    ‚Üì\n",
    "LOAD (Cargar)\n",
    "    ‚Üì\n",
    "    ‚Ä¢ Insertar en Data Warehouse\n",
    "    ‚Ä¢ Actualizar dimensiones\n",
    "    ‚Ä¢ Validar integridad\n",
    "```\n",
    "\n",
    "### üéì Principios de ETL Profesional\n",
    "\n",
    "1. **Idempotencia:** Ejecutar el proceso m√∫ltiples veces da el mismo resultado\n",
    "2. **Logging:** Registrar cada paso para debugging\n",
    "3. **Error Handling:** Manejar fallos gracefully\n",
    "4. **Performance:** Procesar datos eficientemente\n",
    "5. **Modularidad:** C√≥digo reutilizable y mantenible\n",
    "\n",
    "### Implementaci√≥n OOP del Data Loader\n",
    "\n",
    "Vamos a construir un **DataLoader** profesional usando Programaci√≥n Orientada a Objetos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import logging\n",
    "from typing import Dict, List, Optional, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('DataLoader')\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    üéì CLASE PRINCIPAL: DataLoader\n",
    "    \n",
    "    Responsabilidades:\n",
    "    1. Conectar a m√∫ltiples fuentes de datos\n",
    "    2. Extraer datos de forma robusta\n",
    "    3. Manejar errores y logging\n",
    "    4. Proporcionar interface consistente\n",
    "    \n",
    "    Ejemplo de uso:\n",
    "        loader = DataLoader()\n",
    "        df = loader.load_from_csv('ventas.csv')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, connection_string: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Constructor de la clase\n",
    "        \n",
    "        Args:\n",
    "            connection_string: String de conexi√≥n a SQL Server (opcional)\n",
    "        \"\"\"\n",
    "        self.connection_string = connection_string\n",
    "        self.connection = None\n",
    "        logger.info(\"‚úÖ DataLoader inicializado\")\n",
    "    \n",
    "    def load_from_csv(self, file_path: str, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        üéì M√âTODO: Carga datos desde archivo CSV\n",
    "        \n",
    "        Este m√©todo demuestra:\n",
    "        - Try-except para manejo de errores\n",
    "        - Logging para rastreabilidad\n",
    "        - Par√°metros opcionales (**kwargs)\n",
    "        - Type hints para claridad\n",
    "        \n",
    "        Args:\n",
    "            file_path: Ruta al archivo CSV\n",
    "            **kwargs: Argumentos adicionales para pd.read_csv\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame con los datos cargados\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: Si el archivo no existe\n",
    "            Exception: Para otros errores\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"üìÇ Cargando archivo CSV: {file_path}\")\n",
    "            \n",
    "            # Verificar que el archivo existe\n",
    "            if not Path(file_path).exists():\n",
    "                raise FileNotFoundError(f\"Archivo no encontrado: {file_path}\")\n",
    "            \n",
    "            # Cargar CSV con par√°metros por defecto + opcionales\n",
    "            default_params = {\n",
    "                'encoding': 'utf-8',\n",
    "                'low_memory': False  # Mejor manejo de tipos de datos\n",
    "            }\n",
    "            default_params.update(kwargs)  # Agregar par√°metros del usuario\n",
    "            \n",
    "            df = pd.read_csv(file_path, **default_params)\n",
    "            \n",
    "            logger.info(f\"‚úÖ CSV cargado: {len(df):,} filas, {len(df.columns)} columnas\")\n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"‚ùå Error: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error inesperado al cargar CSV: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def load_from_excel(self, file_path: str, sheet_name: str = None, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Carga datos desde archivo Excel\n",
    "        \n",
    "        üí° TIP: Excel puede ser m√°s lento que CSV para archivos grandes.\n",
    "               Considera convertir a CSV si tienes problemas de performance.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"üìä Cargando archivo Excel: {file_path}\")\n",
    "            \n",
    "            if not Path(file_path).exists():\n",
    "                raise FileNotFoundError(f\"Archivo no encontrado: {file_path}\")\n",
    "            \n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name, **kwargs)\n",
    "            \n",
    "            logger.info(f\"‚úÖ Excel cargado: {len(df):,} filas\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error al cargar Excel: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def connect_to_database(self) -> bool:\n",
    "        \"\"\"\n",
    "        Establece conexi√≥n con SQL Server\n",
    "        \n",
    "        Returns:\n",
    "            True si la conexi√≥n fue exitosa\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.connection_string:\n",
    "                logger.warning(\"‚ö†Ô∏è  No hay connection string configurada\")\n",
    "                return False\n",
    "            \n",
    "            logger.info(\"üîå Conectando a base de datos...\")\n",
    "            self.connection = pyodbc.connect(self.connection_string)\n",
    "            logger.info(\"‚úÖ Conexi√≥n establecida\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error de conexi√≥n: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def load_from_sql(self, query: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Ejecuta query SQL y retorna DataFrame\n",
    "        \n",
    "        üéì CONCEPTO: Este m√©todo demuestra integraci√≥n con bases de datos.\n",
    "                    En producci√≥n, siempre usa conexiones parametrizadas\n",
    "                    para prevenir SQL injection.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.connection:\n",
    "                self.connect_to_database()\n",
    "            \n",
    "            logger.info(f\"üîç Ejecutando query: {query[:50]}...\")\n",
    "            df = pd.read_sql(query, self.connection)\n",
    "            logger.info(f\"‚úÖ Query ejecutada: {len(df):,} filas\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error en query SQL: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Destructor: Cierra conexi√≥n al destruir el objeto\"\"\"\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "            logger.info(\"üîå Conexi√≥n cerrada\")\n",
    "\n",
    "\n",
    "# Demostraci√≥n de uso\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéì DEMOSTRACI√ìN: Uso del DataLoader\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "loader = DataLoader()\n",
    "\n",
    "# Simular carga de CSV\n",
    "print(\"\\n1Ô∏è‚É£ Ejemplo de carga desde CSV:\")\n",
    "print(\"   loader.load_from_csv('datos_ventas.csv')\")\n",
    "print(\"   ‚Üí Carga datos con validaci√≥n y logging autom√°tico\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Ejemplo de carga desde Excel:\")\n",
    "print(\"   loader.load_from_excel('reporte.xlsx', sheet_name='Ventas')\")\n",
    "print(\"   ‚Üí Soporta m√∫ltiples hojas\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Ejemplo de query SQL:\")\n",
    "print(\"   loader.load_from_sql('SELECT * FROM dim_customer WHERE is_active = 1')\")\n",
    "print(\"   ‚Üí Extrae datos directamente de base de datos\")\n",
    "\n",
    "print(\"\\nüí° Ventajas del dise√±o OOP:\")\n",
    "print(\"   ‚úÖ C√≥digo reutilizable\")\n",
    "print(\"   ‚úÖ F√°cil de mantener y extender\")\n",
    "print(\"   ‚úÖ Logging y error handling incorporados\")\n",
    "print(\"   ‚úÖ Interface consistente para m√∫ltiples fuentes\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Ejercicio Pr√°ctico\n",
    "\n",
    "Vamos a crear datos de muestra y usar nuestro DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Crear datos de muestra\n",
    "print(\"üìù Creando datos de muestra...\\n\")\n",
    "\n",
    "# Simular datos de ventas\n",
    "ventas_muestra = pd.DataFrame({\n",
    "    'transaction_id': range(1, 11),\n",
    "    'date': pd.date_range('2024-01-01', periods=10),\n",
    "    'product_name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Laptop'] * 2,\n",
    "    'quantity': [2, 5, 3, 1, 1, 3, 10, 2, 1, 4],\n",
    "    'unit_price': [999.99, 29.99, 79.99, 299.99, 999.99] * 2,\n",
    "    'customer_name': ['Cliente A', 'Cliente B', 'Cliente C', 'Cliente D', 'Cliente E'] * 2\n",
    "})\n",
    "\n",
    "# Guardar como CSV temporal\n",
    "ventas_muestra.to_csv('/tmp/ventas_ejemplo.csv', index=False)\n",
    "print(\"‚úÖ Archivo CSV creado: /tmp/ventas_ejemplo.csv\")\n",
    "\n",
    "# Usar el DataLoader para cargar el archivo\n",
    "print(\"\\nüìÇ Usando DataLoader para cargar datos...\\n\")\n",
    "loader = DataLoader()\n",
    "df_ventas = loader.load_from_csv('/tmp/ventas_ejemplo.csv')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\nüìä Datos cargados:\")\n",
    "print(df_ventas)\n",
    "\n",
    "# Calcular m√©tricas b√°sicas\n",
    "print(\"\\nüí∞ An√°lisis r√°pido:\")\n",
    "df_ventas['revenue'] = df_ventas['quantity'] * df_ventas['unit_price']\n",
    "print(f\"   Revenue total: ${df_ventas['revenue'].sum():,.2f}\")\n",
    "print(f\"   Transacciones: {len(df_ventas)}\")\n",
    "print(f\"   Clientes √∫nicos: {df_ventas['customer_name'].nunique()}\")\n",
    "print(f\"   Productos √∫nicos: {df_ventas['product_name'].nunique()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Checkpoint de Aprendizaje #1\n",
    "\n",
    "### ¬øQu√© hemos aprendido hasta ahora?\n",
    "\n",
    "‚úÖ **Fundamentos de Star Schema**\n",
    "  - Diferencia entre dimensiones y hechos\n",
    "  - Por qu√© usar star schema\n",
    "  - Mejores pr√°cticas de dise√±o\n",
    "\n",
    "‚úÖ **Dimensi√≥n de Fecha**\n",
    "  - Por qu√© es cr√≠tica\n",
    "  - C√≥mo generarla program√°ticamente\n",
    "  - Atributos esenciales (a√±o, mes, trimestre, fiscal)\n",
    "\n",
    "‚úÖ **ETL con Python**\n",
    "  - Concepto de Extract, Transform, Load\n",
    "  - Dise√±o OOP para c√≥digo profesional\n",
    "  - Manejo de errores y logging\n",
    "  - Carga desde m√∫ltiples fuentes\n",
    "\n",
    "### üí™ Siguiente Nivel\n",
    "\n",
    "En las pr√≥ximas secciones vamos a:\n",
    "- Transformar datos y calcular KPIs\n",
    "- Validar calidad de datos\n",
    "- Escribir SQL avanzado\n",
    "- Crear dashboards en Power BI y web\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
